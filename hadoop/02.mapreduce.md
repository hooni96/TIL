MapReduce
=========
간략한 설명
--------
**역사**
> *대규모 클러스터에서 데이터프로세스 simplified 할 수 있는 방법으로 Googled에서 제시한 방법*
> 
> *지금은 성능 좋은게 많아져서 사용하지 않지만 하단부는 MR로 바탕이 되어있다.*

**역할**
> Automatic parallelization and distibution
> 
> Fault-tolerance *실패가 있어도 시간이 걸릴 뿐 전체 시스템 돌아가는 데 문제가 되지 않게 해줌*
> 
> I/O Scheduling, Status and monitoring

실습
---
개발자는 map, redue 함수만 코딩해주면 많은 클러스터에서 자동으로 돌아감

**map (k1, v1) -> list(k2, v2)** key, value 쌍으로 입력을 넣어, 내가 원하는 key-value list로 반환한다.

**reduce (k2, list(v2)) -> list(v2)** mapping으로 반환된 list를 넣어, 원하는 연산이 들어간 reducing을 거쳐 계산 값을 반환받는다.

보통 Java를 이용해 개발하지만, Streaming 이용해 다른 언어로 개발 가능하고, 나는 python으로 개발할 것이다.

ssh root계정으로 HDP에 접속해 PIP와 MRJob 라이브러리를 설치해준다.
```
$ yum install python-pip
$ pip install mrjob
```
Python으로 MR code 작성한다. ssh로 접속할 땐 [vim editor](https://opentutorials.org/course/730)를 사용한다.

작성한 맵듀스를 사용하는 방법은 두가지다.

###### 예시 : [단어 수 세기](https://github.com/hooni96/TIL/blob/main/hadoop/wordcount.py)
- **Local에서 실행**
```
$ python wordcount.py movielens/ml-latest-small/README.txt
$ python wordcount.py movielens/ml-latest-small/README.txt > output.txt
```
- **Hadoop에서 실행**
 1. Docker Ubuntu Local 위에 파일 가져다 쓰기!! ***<로컬 파일주소 절대주소로 다 안 적으면 오류나더라는...>***

`$ python wordcount.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar /home/maria_dev/ml-latest-small/README.txt`

 2. hadoop에 있는 파일로 실행! ***<대소문자 구분해서 정확히 적어줘야 동작함>***

`$ python wordcount.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar hdfs:///user/maria_dev/ml-latest-small/README.txt`

 3. hadoop에 있는 파일로 실행하고 결과도 hadoop에 저장 ***<앞에 output위치랑 폴더 명 정하면 됨!>***

`$ python wordcount.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar --output-dir=hdfs:///user/maria_dev/mapreduce/output_ml_latest__small hdfs:///user/maria_dev/ml-latest-small/README.txt`
